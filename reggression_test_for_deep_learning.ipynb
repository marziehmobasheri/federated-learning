{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2LA75jQ2ZPN",
        "outputId": "eb47b772-cece-40bf-fa16-c6dda1b84d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/500], Loss: 0.0942\n",
            "Epoch [100/500], Loss: 0.0870\n",
            "Epoch [150/500], Loss: 0.0845\n",
            "Epoch [200/500], Loss: 0.0813\n",
            "Epoch [250/500], Loss: 0.0775\n",
            "Epoch [300/500], Loss: 0.0750\n",
            "Epoch [350/500], Loss: 0.0703\n",
            "Epoch [400/500], Loss: 0.0667\n",
            "Epoch [450/500], Loss: 0.0608\n",
            "Epoch [500/500], Loss: 0.0539\n",
            "Final Loss: 0.0539\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size1, hidden_size2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Generate some random data for training\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 5)  # 100 samples, 5 features\n",
        "y = np.random.rand(100, 1)   # 100 samples, 1 target\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.FloatTensor(X)\n",
        "y_train = torch.FloatTensor(y)\n",
        "\n",
        "# Initialize the model\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size1 = 10\n",
        "hidden_size2 = 5\n",
        "model = RegressionModel(input_size, hidden_size1, hidden_size2)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 50 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_train)\n",
        "    final_loss = criterion(y_pred, y_train)\n",
        "    print(f'Final Loss: {final_loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size1, hidden_size2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Generate some random data for training and testing\n",
        "np.random.seed(0)\n",
        "X_train = np.random.rand(100, 5)  # 100 samples, 5 features\n",
        "y_train = np.random.rand(100, 1)   # 100 samples, 1 target\n",
        "X_test = np.random.rand(20, 5)     # 20 samples for testing\n",
        "y_test = np.random.rand(20, 1)      # 20 target values for testing\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_test = torch.FloatTensor(y_test)\n",
        "\n",
        "# Initialize the model\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size1 = 10\n",
        "hidden_size2 = 5\n",
        "model = RegressionModel(input_size, hidden_size1, hidden_size2)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 50 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_train = model(X_train)\n",
        "    train_loss = criterion(y_pred_train, y_train)\n",
        "    print(f'Training Loss: {train_loss.item():.4f}')\n",
        "\n",
        "    y_pred_test = model(X_test)\n",
        "    test_loss = criterion(y_pred_test, y_test)\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2QTAks-2zjr",
        "outputId": "4f200a2d-d283-4f58-ea97-965115a7ea95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/500], Loss: 0.0846\n",
            "Epoch [100/500], Loss: 0.0676\n",
            "Epoch [150/500], Loss: 0.0445\n",
            "Epoch [200/500], Loss: 0.0382\n",
            "Epoch [250/500], Loss: 0.0369\n",
            "Epoch [300/500], Loss: 0.0352\n",
            "Epoch [350/500], Loss: 0.0336\n",
            "Epoch [400/500], Loss: 0.0326\n",
            "Epoch [450/500], Loss: 0.0312\n",
            "Epoch [500/500], Loss: 0.0301\n",
            "Training Loss: 0.0299\n",
            "Test Loss: 0.2053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size1, hidden_size2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Generate some random data for training and testing\n",
        "np.random.seed(0)\n",
        "X_train = np.random.rand(100, 5)  # 100 samples, 5 features\n",
        "y_train = np.random.rand(100, 1)   # 100 samples, 1 target\n",
        "X_test = np.random.rand(20, 5)     # 20 samples for testing\n",
        "y_test = np.random.rand(20, 1)      # 20 target values for testing\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_test = torch.FloatTensor(y_test)\n",
        "\n",
        "# Initialize the model\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size1 = 10\n",
        "hidden_size2 = 5\n",
        "model = RegressionModel(input_size, hidden_size1, hidden_size2)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 50 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_train = model(X_train)\n",
        "    train_loss = criterion(y_pred_train, y_train)\n",
        "    print(f'Training Loss: {train_loss.item():.4f}')\n",
        "\n",
        "    y_pred_test = model(X_test)\n",
        "    test_loss = criterion(y_pred_test, y_test)\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n",
        "\n",
        "# Predict for new input data\n",
        "new_input = np.random.rand(1, 5)  # New input data with 5 features\n",
        "new_input = torch.FloatTensor(new_input)\n",
        "with torch.no_grad():\n",
        "    prediction = model(new_input)\n",
        "    print(f'Prediction for new input: {prediction.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFh1lQ1W3S19",
        "outputId": "7bad1a12-b834-4b2f-8c07-b5b2772fcee5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/500], Loss: 0.0916\n",
            "Epoch [100/500], Loss: 0.0879\n",
            "Epoch [150/500], Loss: 0.0857\n",
            "Epoch [200/500], Loss: 0.0827\n",
            "Epoch [250/500], Loss: 0.0793\n",
            "Epoch [300/500], Loss: 0.0765\n",
            "Epoch [350/500], Loss: 0.0744\n",
            "Epoch [400/500], Loss: 0.0725\n",
            "Epoch [450/500], Loss: 0.0715\n",
            "Epoch [500/500], Loss: 0.0711\n",
            "Training Loss: 0.0711\n",
            "Test Loss: 0.1024\n",
            "Prediction for new input: 0.5972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Define the model\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size1, hidden_size2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Generate some random data for training and testing\n",
        "np.random.seed(0)\n",
        "X_train = np.random.rand(100, 5)  # 100 samples, 5 features\n",
        "y_train = np.random.rand(100, 1)   # 100 samples, 1 target\n",
        "X_test = np.random.rand(20, 5)     # 20 samples for testing\n",
        "y_test = np.random.rand(20, 1)     # 20 target values for testing\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_test = torch.FloatTensor(y_test)\n",
        "\n",
        "print(\"X_train:\", X_train)\n",
        "print(\"y_train:\", y_train)\n",
        "print(\"X_test:\", X_test)\n",
        "print(\"y_test:\", y_test)\n",
        "\n",
        "# Initialize the model\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size1 = 10\n",
        "hidden_size2 = 5\n",
        "model = RegressionModel(input_size, hidden_size1, hidden_size2)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 50 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_train = model(X_train)\n",
        "    train_loss = criterion(y_pred_train, y_train)\n",
        "    print(f'Training Loss: {train_loss.item():.4f}')\n",
        "\n",
        "    y_pred_test = model(X_test)\n",
        "    test_loss = criterion(y_pred_test, y_test)\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n",
        "\n",
        "# Predict for new input data\n",
        "new_input = np.random.rand(1, 5)  # New input data with 5 features\n",
        "new_input = torch.FloatTensor(new_input)\n",
        "print(\"New Input:\", new_input)\n",
        "with torch.no_grad():\n",
        "    prediction = model(new_input)\n",
        "    print(f'Prediction for new input: {prediction.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlW-GR_73l9Z",
        "outputId": "c1378afb-7758-490a-e96b-13473feaedeb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: tensor([[0.5488, 0.7152, 0.6028, 0.5449, 0.4237],\n",
            "        [0.6459, 0.4376, 0.8918, 0.9637, 0.3834],\n",
            "        [0.7917, 0.5289, 0.5680, 0.9256, 0.0710],\n",
            "        [0.0871, 0.0202, 0.8326, 0.7782, 0.8700],\n",
            "        [0.9786, 0.7992, 0.4615, 0.7805, 0.1183],\n",
            "        [0.6399, 0.1434, 0.9447, 0.5218, 0.4147],\n",
            "        [0.2646, 0.7742, 0.4562, 0.5684, 0.0188],\n",
            "        [0.6176, 0.6121, 0.6169, 0.9437, 0.6818],\n",
            "        [0.3595, 0.4370, 0.6976, 0.0602, 0.6668],\n",
            "        [0.6706, 0.2104, 0.1289, 0.3154, 0.3637],\n",
            "        [0.5702, 0.4386, 0.9884, 0.1020, 0.2089],\n",
            "        [0.1613, 0.6531, 0.2533, 0.4663, 0.2444],\n",
            "        [0.1590, 0.1104, 0.6563, 0.1382, 0.1966],\n",
            "        [0.3687, 0.8210, 0.0971, 0.8379, 0.0961],\n",
            "        [0.9765, 0.4687, 0.9768, 0.6048, 0.7393],\n",
            "        [0.0392, 0.2828, 0.1202, 0.2961, 0.1187],\n",
            "        [0.3180, 0.4143, 0.0641, 0.6925, 0.5666],\n",
            "        [0.2654, 0.5232, 0.0939, 0.5759, 0.9293],\n",
            "        [0.3186, 0.6674, 0.1318, 0.7163, 0.2894],\n",
            "        [0.1832, 0.5865, 0.0201, 0.8289, 0.0047],\n",
            "        [0.6778, 0.2700, 0.7352, 0.9622, 0.2488],\n",
            "        [0.5762, 0.5920, 0.5723, 0.2231, 0.9527],\n",
            "        [0.4471, 0.8464, 0.6995, 0.2974, 0.8138],\n",
            "        [0.3965, 0.8811, 0.5813, 0.8817, 0.6925],\n",
            "        [0.7253, 0.5013, 0.9561, 0.6440, 0.4239],\n",
            "        [0.6064, 0.0192, 0.3016, 0.6602, 0.2901],\n",
            "        [0.6180, 0.4288, 0.1355, 0.2983, 0.5700],\n",
            "        [0.5909, 0.5743, 0.6532, 0.6521, 0.4314],\n",
            "        [0.8965, 0.3676, 0.4359, 0.8919, 0.8062],\n",
            "        [0.7039, 0.1002, 0.9195, 0.7142, 0.9988],\n",
            "        [0.1494, 0.8681, 0.1625, 0.6156, 0.1238],\n",
            "        [0.8480, 0.8073, 0.5691, 0.4072, 0.0692],\n",
            "        [0.6974, 0.4535, 0.7221, 0.8664, 0.9755],\n",
            "        [0.8558, 0.0117, 0.3600, 0.7300, 0.1716],\n",
            "        [0.5210, 0.0543, 0.2000, 0.0185, 0.7937],\n",
            "        [0.2239, 0.3454, 0.9281, 0.7044, 0.0318],\n",
            "        [0.1647, 0.6215, 0.5772, 0.2379, 0.9342],\n",
            "        [0.6140, 0.5356, 0.5899, 0.7301, 0.3119],\n",
            "        [0.3982, 0.2098, 0.1862, 0.9444, 0.7396],\n",
            "        [0.4905, 0.2274, 0.2544, 0.0580, 0.4344],\n",
            "        [0.3118, 0.6963, 0.3778, 0.1796, 0.0247],\n",
            "        [0.0672, 0.6794, 0.4537, 0.5366, 0.8967],\n",
            "        [0.9903, 0.2169, 0.6631, 0.2633, 0.0207],\n",
            "        [0.7584, 0.3200, 0.3835, 0.5883, 0.8310],\n",
            "        [0.6290, 0.8727, 0.2735, 0.7980, 0.1856],\n",
            "        [0.9528, 0.6875, 0.2155, 0.9474, 0.7309],\n",
            "        [0.2539, 0.2133, 0.5182, 0.0257, 0.2075],\n",
            "        [0.4247, 0.3742, 0.4636, 0.2776, 0.5868],\n",
            "        [0.8639, 0.1175, 0.5174, 0.1321, 0.7169],\n",
            "        [0.3961, 0.5654, 0.1833, 0.1448, 0.4881],\n",
            "        [0.3556, 0.9404, 0.7653, 0.7487, 0.9037],\n",
            "        [0.0834, 0.5522, 0.5845, 0.9619, 0.2921],\n",
            "        [0.2408, 0.1003, 0.0164, 0.9295, 0.6699],\n",
            "        [0.7852, 0.2817, 0.5864, 0.0640, 0.4856],\n",
            "        [0.9775, 0.8765, 0.3382, 0.9616, 0.2317],\n",
            "        [0.9493, 0.9414, 0.7992, 0.6304, 0.8743],\n",
            "        [0.2930, 0.8489, 0.6179, 0.0132, 0.3472],\n",
            "        [0.1481, 0.9818, 0.4784, 0.4974, 0.6395],\n",
            "        [0.3686, 0.1369, 0.8221, 0.1898, 0.5113],\n",
            "        [0.2243, 0.0978, 0.8622, 0.9729, 0.9608],\n",
            "        [0.9066, 0.7740, 0.3331, 0.0811, 0.4072],\n",
            "        [0.2322, 0.1325, 0.0534, 0.7256, 0.0114],\n",
            "        [0.7706, 0.1469, 0.0795, 0.0896, 0.6720],\n",
            "        [0.2454, 0.4205, 0.5574, 0.8606, 0.7270],\n",
            "        [0.2703, 0.1315, 0.0554, 0.3016, 0.2621],\n",
            "        [0.4561, 0.6833, 0.6956, 0.2835, 0.3799],\n",
            "        [0.1812, 0.7885, 0.0568, 0.6970, 0.7787],\n",
            "        [0.7774, 0.2594, 0.3738, 0.5876, 0.2728],\n",
            "        [0.3709, 0.1971, 0.4599, 0.0446, 0.7998],\n",
            "        [0.0770, 0.5188, 0.3068, 0.5775, 0.9594],\n",
            "        [0.6456, 0.0354, 0.4304, 0.5100, 0.5362],\n",
            "        [0.6814, 0.2776, 0.1289, 0.3927, 0.9564],\n",
            "        [0.1871, 0.9040, 0.5438, 0.4569, 0.8820],\n",
            "        [0.4586, 0.7242, 0.3990, 0.9040, 0.6900],\n",
            "        [0.6996, 0.3277, 0.7568, 0.6361, 0.2400],\n",
            "        [0.1605, 0.7964, 0.9592, 0.4581, 0.5910],\n",
            "        [0.8577, 0.4572, 0.9519, 0.5758, 0.8208],\n",
            "        [0.9088, 0.8155, 0.1594, 0.6289, 0.3984],\n",
            "        [0.0627, 0.4240, 0.2587, 0.8490, 0.0333],\n",
            "        [0.9590, 0.3554, 0.3567, 0.0163, 0.1852],\n",
            "        [0.4013, 0.9293, 0.0996, 0.9453, 0.8695],\n",
            "        [0.4542, 0.3267, 0.2327, 0.6145, 0.0331],\n",
            "        [0.0156, 0.4288, 0.0681, 0.2519, 0.2212],\n",
            "        [0.2532, 0.1311, 0.0120, 0.1155, 0.6185],\n",
            "        [0.9743, 0.9903, 0.4091, 0.1630, 0.6388],\n",
            "        [0.4903, 0.9894, 0.0653, 0.7832, 0.2884],\n",
            "        [0.2414, 0.6625, 0.2461, 0.6659, 0.5173],\n",
            "        [0.4241, 0.5547, 0.2871, 0.7066, 0.4149],\n",
            "        [0.3605, 0.8287, 0.9250, 0.0460, 0.2326],\n",
            "        [0.3485, 0.8150, 0.9855, 0.9690, 0.9049],\n",
            "        [0.2966, 0.9920, 0.2494, 0.1059, 0.9510],\n",
            "        [0.2334, 0.6898, 0.0584, 0.7307, 0.8817],\n",
            "        [0.2724, 0.3791, 0.3743, 0.7488, 0.2378],\n",
            "        [0.1719, 0.4493, 0.3045, 0.8392, 0.2377],\n",
            "        [0.5024, 0.9426, 0.6340, 0.8673, 0.9402],\n",
            "        [0.7508, 0.6996, 0.9680, 0.9944, 0.4518],\n",
            "        [0.0709, 0.2928, 0.1524, 0.4175, 0.1313],\n",
            "        [0.6041, 0.3828, 0.8954, 0.9678, 0.5469],\n",
            "        [0.2748, 0.5922, 0.8968, 0.4067, 0.5521],\n",
            "        [0.2717, 0.4554, 0.4017, 0.2484, 0.5059]])\n",
            "y_train: tensor([[0.3104],\n",
            "        [0.3730],\n",
            "        [0.5250],\n",
            "        [0.7506],\n",
            "        [0.3335],\n",
            "        [0.9242],\n",
            "        [0.8623],\n",
            "        [0.0487],\n",
            "        [0.2536],\n",
            "        [0.4461],\n",
            "        [0.1046],\n",
            "        [0.3485],\n",
            "        [0.7401],\n",
            "        [0.6805],\n",
            "        [0.6224],\n",
            "        [0.7105],\n",
            "        [0.2049],\n",
            "        [0.3417],\n",
            "        [0.6762],\n",
            "        [0.8792],\n",
            "        [0.5437],\n",
            "        [0.2827],\n",
            "        [0.0302],\n",
            "        [0.7103],\n",
            "        [0.0079],\n",
            "        [0.3727],\n",
            "        [0.5305],\n",
            "        [0.9221],\n",
            "        [0.0895],\n",
            "        [0.4059],\n",
            "        [0.0243],\n",
            "        [0.3426],\n",
            "        [0.6222],\n",
            "        [0.2791],\n",
            "        [0.2097],\n",
            "        [0.1157],\n",
            "        [0.5771],\n",
            "        [0.6953],\n",
            "        [0.6720],\n",
            "        [0.9489],\n",
            "        [0.0027],\n",
            "        [0.6472],\n",
            "        [0.6004],\n",
            "        [0.5887],\n",
            "        [0.9628],\n",
            "        [0.0169],\n",
            "        [0.6965],\n",
            "        [0.8137],\n",
            "        [0.5098],\n",
            "        [0.3340],\n",
            "        [0.7908],\n",
            "        [0.0972],\n",
            "        [0.4420],\n",
            "        [0.5200],\n",
            "        [0.6940],\n",
            "        [0.0909],\n",
            "        [0.2278],\n",
            "        [0.4103],\n",
            "        [0.6233],\n",
            "        [0.8870],\n",
            "        [0.6188],\n",
            "        [0.1335],\n",
            "        [0.9806],\n",
            "        [0.8718],\n",
            "        [0.5027],\n",
            "        [0.9223],\n",
            "        [0.5414],\n",
            "        [0.9233],\n",
            "        [0.8299],\n",
            "        [0.9683],\n",
            "        [0.9198],\n",
            "        [0.0360],\n",
            "        [0.1748],\n",
            "        [0.3891],\n",
            "        [0.9521],\n",
            "        [0.3000],\n",
            "        [0.1605],\n",
            "        [0.8863],\n",
            "        [0.4464],\n",
            "        [0.9079],\n",
            "        [0.1602],\n",
            "        [0.6611],\n",
            "        [0.4403],\n",
            "        [0.0765],\n",
            "        [0.6965],\n",
            "        [0.2474],\n",
            "        [0.0396],\n",
            "        [0.0599],\n",
            "        [0.0611],\n",
            "        [0.9077],\n",
            "        [0.7399],\n",
            "        [0.8981],\n",
            "        [0.6726],\n",
            "        [0.5289],\n",
            "        [0.3044],\n",
            "        [0.9980],\n",
            "        [0.3622],\n",
            "        [0.4706],\n",
            "        [0.3782],\n",
            "        [0.9795]])\n",
            "X_test: tensor([[0.1747, 0.3280, 0.6803, 0.0632, 0.6072],\n",
            "        [0.4776, 0.2840, 0.2384, 0.5145, 0.3679],\n",
            "        [0.4565, 0.3375, 0.9705, 0.1334, 0.0968],\n",
            "        [0.3434, 0.5910, 0.6592, 0.3973, 0.9993],\n",
            "        [0.3519, 0.7214, 0.6376, 0.8131, 0.9762],\n",
            "        [0.8898, 0.7646, 0.6982, 0.3355, 0.1477],\n",
            "        [0.0626, 0.2419, 0.4323, 0.5220, 0.7731],\n",
            "        [0.9587, 0.1173, 0.1070, 0.5897, 0.7454],\n",
            "        [0.8482, 0.9358, 0.9834, 0.3998, 0.3803],\n",
            "        [0.1478, 0.6849, 0.6568, 0.8621, 0.0973],\n",
            "        [0.4978, 0.5811, 0.2416, 0.1690, 0.8596],\n",
            "        [0.0585, 0.4706, 0.1158, 0.4571, 0.9800],\n",
            "        [0.4237, 0.8571, 0.1173, 0.2713, 0.4038],\n",
            "        [0.3998, 0.6714, 0.3447, 0.7138, 0.6392],\n",
            "        [0.3992, 0.4318, 0.6145, 0.0700, 0.8224],\n",
            "        [0.6534, 0.7263, 0.5369, 0.1105, 0.4050],\n",
            "        [0.4054, 0.3210, 0.0300, 0.7373, 0.1098],\n",
            "        [0.6063, 0.7032, 0.6348, 0.9591, 0.1033],\n",
            "        [0.8672, 0.0292, 0.5349, 0.4042, 0.5242],\n",
            "        [0.3651, 0.1906, 0.0191, 0.5181, 0.8428]])\n",
            "y_test: tensor([[0.3732],\n",
            "        [0.2229],\n",
            "        [0.0805],\n",
            "        [0.0853],\n",
            "        [0.2214],\n",
            "        [0.1000],\n",
            "        [0.2650],\n",
            "        [0.0661],\n",
            "        [0.0656],\n",
            "        [0.8563],\n",
            "        [0.1621],\n",
            "        [0.5597],\n",
            "        [0.7735],\n",
            "        [0.4564],\n",
            "        [0.1534],\n",
            "        [0.1996],\n",
            "        [0.4330],\n",
            "        [0.5282],\n",
            "        [0.3494],\n",
            "        [0.7815]])\n",
            "Epoch [50/500], Loss: 0.0984\n",
            "Epoch [100/500], Loss: 0.0925\n",
            "Epoch [150/500], Loss: 0.0902\n",
            "Epoch [200/500], Loss: 0.0890\n",
            "Epoch [250/500], Loss: 0.0884\n",
            "Epoch [300/500], Loss: 0.0876\n",
            "Epoch [350/500], Loss: 0.0869\n",
            "Epoch [400/500], Loss: 0.0852\n",
            "Epoch [450/500], Loss: 0.0817\n",
            "Epoch [500/500], Loss: 0.0760\n",
            "Training Loss: 0.0759\n",
            "Test Loss: 0.0852\n",
            "New Input: tensor([[0.7510, 0.9272, 0.0290, 0.8957, 0.3926]])\n",
            "Prediction for new input: 0.3818\n"
          ]
        }
      ]
    }
  ]
}